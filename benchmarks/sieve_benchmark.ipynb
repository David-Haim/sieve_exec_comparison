{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044c8774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed62b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ff60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "benches = [ 'sieve' ]\n",
    "\n",
    "# Alphabetical order\n",
    "# pools = ['_async_fun', '_cc_fun', '_direct_fun', '_p2300_fun', '_tbb_fun']\n",
    "\n",
    "# Performance order\n",
    "pools = ['_cc_fun', '_tbb_fun', '_direct_fun', '_async_fun', '_p2300_fun']\n",
    "\n",
    "sizes = [100000000, 1000000000]\n",
    "\n",
    "# If you just want to compare different frameworks on one block size, set blocks = [100]\n",
    "blocks = [100]\n",
    "\n",
    "# Otherwise, if you want to find the best block size for each framework, \n",
    "# set blocks to a list of different block sizes that you want to benchmark with\n",
    "# blocks = [10, 100, 1000, 10000, 100000, 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ba936",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('cd .. ; make clean ; make -j 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e18f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in benches:\n",
    "    for p in pools:\n",
    "        os.system('/bin/rm -f ' + b + p + '.exe')\n",
    "        os.system('cp ../' + b + p + '.exe .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4211b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in benches:\n",
    "    for p in pools:\n",
    "        bin = './' + b + p + '.exe'\n",
    "        for s in sizes:\n",
    "            for bl in blocks:\n",
    "                if (p == '_seq' and bl != 1000000):\n",
    "                    continue\n",
    "                if (s >= bl*1000):\n",
    "                    args = str(s) + ' ' + str(bl)\n",
    "                    logfile = b + p + '_' + str(s) + '_' + str(bl) +'_out.txt'\n",
    "                    os.system('/bin/rm -f ' + logfile)\n",
    "                    for i in range(16):\n",
    "                        os.system(bin + ' ' + args + ' >> ' + logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee047009",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in benches:\n",
    "    for p in pools:\n",
    "        for s in sizes:\n",
    "            for bl in blocks:\n",
    "                if (p == '_seq' and bl != 1000000):\n",
    "                    continue\n",
    "                if (s >= bl*1000):\n",
    "                    listname = b + p + '_' + str(s) + '_' + str(bl)\n",
    "                    exec(listname + ' = []')\n",
    "                    logfile = b + p + '_' + str(s) + '_' + str(bl) +'_out.txt'\n",
    "                    with open(logfile) as log:\n",
    "                        lines = log.readlines()\n",
    "                        for line in lines:\n",
    "                            if 'Time using char' in line:\n",
    "                                l = line.split(':')\n",
    "                                num = int(l[1])\n",
    "                                exec(listname + '.append(num)')\n",
    "                    exec(listname + '_mean = np.mean(' + listname + ')')\n",
    "                    exec(listname + '_std = np.std(' + listname + ')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d2eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_vs_block_size(name, mean_times, std_times, blocks):\n",
    "    fig, ax = plt.subplots(figsize=(16,9))\n",
    "    x_pos = np.arange(len(blocks))\n",
    "    ax.bar(x_pos, mean_times, yerr=std_times, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.set_ylabel('Run time')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(blocks, rotation= 90)\n",
    "    ax.set_title('Sieve Performance Comparison: ' + name)\n",
    "    ax.yaxis.grid(True)\n",
    "\n",
    "    # Save the figure and show\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('bar_plot_' + name + '_.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6010b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each framework, compare performance of different block sizes\n",
    "for b in benches:\n",
    "    for p in pools:\n",
    "        if (p == '_seq'):\n",
    "            continue\n",
    "        for s in sizes:\n",
    "            listname = b + p + '_' + str(s)\n",
    "            listname_mean = b + p + '_' + str(s) + '_mean'\n",
    "            listname_std = b + p + '_' + str(s) + 'std'\n",
    "            exec(listname_mean + ' = []')\n",
    "            exec(listname_std + ' = []')\n",
    "            xbl = []\n",
    "            \n",
    "            for bl in blocks:\n",
    "                blockname_mean = b + p + '_' + str(s) + '_' + str(bl) + '_mean'\n",
    "                blockname_std = b + p + '_' + str(s) + '_' + str(bl) + '_std'\n",
    "                if (s >= bl*1000):\n",
    "                    exec(listname_mean + '.append(' + blockname_mean + ')' )\n",
    "                    exec(listname_std + '.append(' + blockname_std + ')' )\n",
    "                    xbl.append(bl)\n",
    "            exec('time_vs_block_size(\"' + listname + '\", ' +listname_mean + ', ' + listname_std + ', ' + 'xbl)')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120367d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different frameworks performance at block size = 100\n",
    "bl = 100\n",
    "for s in sizes:\n",
    "    \n",
    "    listname = '_' + str(s)\n",
    "    listname_mean = '_' + str(s) + '_mean'\n",
    "    listname_std = '_' + str(s) + 'std'\n",
    "    exec(listname_mean + ' = []')\n",
    "    exec(listname_std + ' = []')\n",
    "    xbl = []\n",
    "    \n",
    "    for b in benches:\n",
    "        for p in pools:\n",
    "            if (p == '_seq'):\n",
    "                continue\n",
    "\n",
    "\n",
    "            \n",
    "            blockname_mean = b + p + '_' + str(s) + '_' + str(bl) + '_mean'\n",
    "            blockname_std = b + p + '_' + str(s) + '_' + str(bl) + '_std'\n",
    "            if (s >= bl*1000):\n",
    "                exec(listname_mean + '.append(' + blockname_mean + ')' )\n",
    "                exec(listname_std + '.append(' + blockname_std + ')' )\n",
    "                xbl.append(b + p)\n",
    "        exec('time_vs_block_size(\"' + listname + '\", ' +listname_mean + ', ' + listname_std + ', ' + 'xbl)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
